package org.gerweck.scala.util.stream

import scala.concurrent._
import scala.concurrent.duration._
import scala.util._

import java.io._
import java.nio.file._
import java.util.zip._

import akka.{ Done, NotUsed }
import akka.stream._
import akka.stream.scaladsl._
import akka.stream.stage._
import akka.util.ByteString

import org.log4s._

import org.gerweck.scala.util.io._

/** Provider of streams that take in zip entries and produces zipped data as output.
  *
  * This offers a number of methods that will create
  * [[http://doc.akka.io/docs/akka/current/scala/stream/ Akka Streams]] stages that can be used
  * to write zip archives. To write to your zip, you will send in a stream of [[ZipStream.Entry]]
  * objects, which are an abstraction of a single entry in a zip archive.
  *
  * The structure of a zip archive requires that a single entry is written to completion once
  * it is started, so you may wish to organize the incoming stream so that it does not emit an
  * `Entry` until its data is available.
  *
  * For example, if the contents of a file are generated by a database query, you may wish to have
  * the completion of the query produce the `Entry` object rather than immediately producing an
  * entry that then executes a query to fetch the required data.
  *
  * @author Sarah Gerweck <sarah.a180@gmail.com>
  */
object ZipStream {
  private[this] val logger = getLogger

  /** The maximum amount of time to allow the zip's write to block. This is an internal operation
    * in a dedicated thread pool, so we're setting it to be effectively infinite. */
  private[this] val outputTimeout = 4.hours

  /** The default buffer size when outputting zipped data as a stream. */
  val defaultFlowBuffer: Option[Int] = Some(8 * 1024)
  /** The default buffer size when writing zipped data to a file. */
  val defaultFileBuffer: Option[Int] = Some(8 * 1024)

  /** An entry to be written into the zip file.
    *
    * @note These are NOT serializable, as they contain a stream `Source`.
    *
    * @param name The name of the file within the archive. If your entry is meant to be in a
    * folder, put the entire path into this field, separated by slashes. (Zip archives doesn't
    * actually have the concept of a folder: they embed any nesting into the entry's name.)
    *
    * @param data the data that you wish to write into this entry. This entire source must be
    * exhausted before the next entry can be started, so a stall here will hold up the entire
    * stream. Similarly, a failure in this stream will fail the entire archive.
    */
  final class Entry(val name: String, val data: Source[ByteString, _]) {
    private[ZipStream] val toActionSource: Source[ZipAction, NotUsed] = {
      Source.single(ZipAction.NewEntry(name)) ++
      data.map(ZipAction.Data) ++
      Source.single(ZipAction.CloseEntry)
    }
  }

  /** A zip compressor that takes in entries and flows out bytes.
    *
    * @param buffer the size (in bytes) of an optional buffer that will hold the zipped data
    * before it is converted into `ByteString` objects. Using a buffer can substantially improve
    * performance, as otherwise you may have many stream elements with just a few bytes in them.
    *
    * @param ec the execution context to use for any callback operations. This context will
    * ''not'' be used for any long-running or blocking operations.
    */
  def asFlow(buffer: Option[Int] = defaultFlowBuffer)(implicit ec: ExecutionContext): Flow[Entry, ByteString, Future[IOResult]] = {
    entryToActionFlow
      .viaMat(actionToBytesFlow(outputTimeout, buffer))(Keep.right)
  }

  /** A zip compressor that takes in entries and writes them to a file.
    *
    * @param path the location of the file to be written.
    *
    * @param existingFile what to do if there is already a file at the provided path.
    *
    * @param buffer the size (in bytes) of an optional buffer that will hold the zipped data
    * before it is written to the file. The OS probably offers output buffering, but this can
    * potentially reduce the number of OS-level writes that need to be made.
    *
    * @param ec the execution context to use for any callback operations. This context will
    * ''not'' be used for any long-running or blocking operations.
    */
  def toFile(path: Path, existingFile: ExistingFile = ExistingFile.Fail, buffer: Option[Int] = defaultFileBuffer)(implicit ec: ExecutionContext): Sink[Entry, Future[IOResult]] = {
    val openOpts = StandardOpenOption.WRITE +: existingFile.openOpts
    val os = { () =>
      addBuffer(buffer) {
        Files.newOutputStream(path, openOpts: _*)
      }
    }
    val outSink: Sink[ZipAction, Future[IOResult]] = simpleZipOutputSink(os)(ec)

    entryToActionFlow
      .toMat(outSink)(Keep.right)
  }

  /* INTERNALS */

  private[this] val entryToActionFlow = {
    Flow[Entry].flatMapConcat(_.toActionSource)
  }

  private[this] def addBuffer(buffer: Option[Int])(os: OutputStream): OutputStream = {
    buffer match {
      case Some(i) => new BufferedOutputStream(os, i)
      case None    => os
    }
  }

  private[this] def actionToBytesFlow(outputTimeout: FiniteDuration, buffer: Option[Int])(implicit ec: ExecutionContext): Flow[ZipAction, ByteString, Future[IOResult]] = {
    Flow.fromGraph {
      val s = StreamConverters.asOutputStream(outputTimeout)
      val z = new ZipOutputSink(ec)
      GraphDSL.create(s, z)(Keep.both) { implicit b => (oss, zos) =>
        import GraphDSL.Implicits._

        val outputStreamConnector = b.add {
          Sink.foreach[(OutputStream, Promise[OutputStream])] { case (os, pos) =>
            pos.success(addBuffer(buffer)(os))
          }
        }
        val materializedStreams = b.materializedValue .map { case (os, (pos, _)) => (os, pos) }

        materializedStreams ~> outputStreamConnector

        FlowShape(zos.in, oss.out)
      }
    }.mapMaterializedValue(_._2._2)
  }

  private[this] def simpleZipOutputSink(os: () => OutputStream)(implicit ec: ExecutionContext): Sink[ZipAction, Future[IOResult]] = {
    Sink.fromGraph {
      GraphDSL.create(new ZipOutputSink(ec)) { implicit b => zos =>
        import GraphDSL.Implicits._

        val completer = b.add {
          Sink.foreach[Promise[OutputStream]] { pos =>
            logger.trace(s"Fulfilling OutputStream promise: $pos")
            val osTry = Future { os() }(ioExecutorContext)
            pos.completeWith(osTry)
          }
        }
        val mpd = b.materializedValue.map(_._1) ~> completer
        SinkShape(zos.in)
      }
    }.mapMaterializedValue(_._2)
  }

  private[this] class ZipOutputSink(ec: ExecutionContext) extends GraphStageWithMaterializedValue[SinkShape[ZipAction], (Promise[OutputStream], Future[IOResult])] {
    import ZipOutputSink._

    val in: Inlet[ZipAction] = Inlet("ZipOutputSink.in")
    override val shape: SinkShape[ZipAction] = SinkShape(in)

    def callbackDispatcher = ec
    /* TODO: Make this configurable. */
    def ioDispatcher = ioExecutorContext

    override def createLogicAndMaterializedValue(inheritedAttributes: Attributes): (GraphStageLogic, (Promise[OutputStream], Future[IOResult])) = {
      val osPromise = Promise[OutputStream]
      val ioResults = Promise[IOResult]
      val logic = {
        new GraphStageLogic(shape) {
          private[this] var streams = Option.empty[Streams]
          private[this] var currentEntry = Option.empty[ZipEntry]
          private[this] var entryCount = 0
          private[this] var outstandingFuture = Option.empty[Future[Done]]

          private[this] def fos = streams.get.fos
          private[this] def zos = streams.get.zos

          override def preStart(): Unit = {
            val streamsFuture = {
              osPromise.future.flatMap { os =>
                Streams(os)(ioDispatcher)
              }(callbackDispatcher)
            }

            streamsFuture.onComplete {
              getAsyncCallback[Try[Streams]] {
                case Success(st) =>
                  streams = Some(st)
                  pull(in)
                case Failure(t) =>
                  ioResults.success(IOResult(entryCount, Failure(t)))
                  failStage(t)
              }.invoke
            }(callbackDispatcher)
          }

          /* We factor this out so we can register just once, reducing the overhead. */
          private[this] def postWriteAction(writeResult: Try[Done]): Unit = {
            writeResult match {
              case Success(_) =>
                pull(in)
              case Failure(t) =>
                failStage(t)
                ioResults.success(IOResult(entryCount, Failure(t)))
            }
            outstandingFuture = None
          }

          setHandler(in, new InHandler {
            /* Normally you would create your callback in `preStart`, but this responds to a
             * future that it purely internal, so it cannot be subject to any race conditions.
             */
            private[this] val postWriteCallback = getAsyncCallback[Try[Done]](postWriteAction)

            override def onPush(): Unit = {
              val input = grab(in)
              val writingFuture =
                Future {
                  /* TODO: Ideally we wouldn't modify `currentEntry` or `entryCount` from out of
                   * the main thread. However, I don't believe it can cause any problems here as
                   * we only have a single future at a time and we never do concurrent access. */
                  input match {
                    case ZipAction.NewEntry(loc) =>
                      currentEntry foreach { ce =>
                        logger.warn(s"Zip entry $ce was not explicitly closed (closing automatically).")
                        zos.closeEntry()
                      }
                      val ze = new ZipEntry(loc)
                      zos.putNextEntry(ze)
                      currentEntry = Some(ze)
                      entryCount += 1
                      Done

                    case ZipAction.Data(bs) =>
                      require(currentEntry.isDefined)
                      zos.write(bs.toArray)
                      Done

                    case ZipAction.CloseEntry =>
                      currentEntry = None
                      zos.closeEntry()
                      Done
                  }
                }(ioDispatcher)
              outstandingFuture = Some(writingFuture)

              writingFuture.onComplete(postWriteCallback.invoke)(callbackDispatcher)
            }

            override def onUpstreamFinish(): Unit = {
              logger.trace("Got upstream finish")
              val closingF = outstandingFuture.getOrElse(Future.successful(Done)) .flatMap { _ =>
                logger.trace(s"Trying to close streams")
                closeStreams()
              }(callbackDispatcher)
              closingF.onComplete {
                case s@Success(Done) =>
                  ioResults.success(IOResult(entryCount, s))
                  logger.trace("Finished processing upstream finish")
                  completeStage()
                case Failure(t) =>
                  ioResults.failure(t)
                  failStage(t)
              }(callbackDispatcher)
            }

            override def onUpstreamFailure(t: Throwable): Unit = {
              closeStreams()
              ioResults.failure(t)
              super.onUpstreamFailure(t)
            }

            private[this] def closeStreams(): Future[Done] = {
              streams match {
                case Some(s) => s.close(ioDispatcher)
                case None    => Future.successful(Done)
              }
            }
          })
        }
      }

      (logic, (osPromise, ioResults.future))
    }
  }

  private[this] object ZipOutputSink {
    private[this] final val forceUnderlyingClose = false
    class Streams(val fos: OutputStream, val zos: ZipOutputStream) {
      def close(ioDispatcher: ExecutionContext): Future[Done] = {
        Future {
          val zc = Try { zos.close() }
          if (forceUnderlyingClose) {
            val fc = Try { fos.close() }
            zc.flatMap(Function.const(fc)).get
          } else {
            zc.get
          }
          Done
        }(ioDispatcher)
      }
    }
    object Streams {
      def apply(fos: OutputStream)(ioDispatcher: ExecutionContext): Future[Streams] = {
        Future {
          var zos = Option.empty[ZipOutputStream]
          Try {
            zos = Some(new ZipOutputStream(fos))
            new Streams(fos, zos.get)
          } .recover { case t =>
            zos.foreach { s => Try(s.close()) }
            Try(fos.close)
            throw t
          } .get
        }(ioDispatcher)
      }
    }
  }

  private[this] sealed trait ZipAction extends Serializable
  private[this] object ZipAction {
    final case class NewEntry(name: String) extends ZipAction
    final case class Data(data: ByteString) extends ZipAction
    final case object CloseEntry extends ZipAction
  }
}
